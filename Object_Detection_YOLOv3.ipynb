{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZrCgF5Ri53T"
      },
      "source": [
        "# **OBJECT DETECTION MODEL**\n",
        "  \n",
        "  By Shreya Tripathi\n",
        "  \n",
        "  ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMqMJhLsU_IK"
      },
      "source": [
        "### First, install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emjTB2V8UzVc",
        "outputId": "4ee8804e-bb08-47d0-f82b-4be42322a5a4"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EE4zNk_VEN3",
        "outputId": "57189688-089a-48b7-89e2-3d3d519c080f"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usc5E2TkVHmn"
      },
      "source": [
        "### Download YOLOv3 configuration, weights, and coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndj4yxJQVF2-",
        "outputId": "68e77788-e132-4811-8d9e-33d8dd04a7aa"
      },
      "outputs": [],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2QmEVLwVNzD",
        "outputId": "a4106861-ec20-4b69-9e13-fc03bccf1d0f"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFlftP5yVPWj",
        "outputId": "3111e0e5-b621-463a-b7d0-0a3c81969d5f"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "YTBHFEbSXTP9",
        "outputId": "a280b429-bae7-47e9-ca42-2d8c11542b47"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the image file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# After uploading, the file should be in the current directory.\n",
        "# Let's check the uploaded file names.\n",
        "image_path = list(uploaded.keys())[0]  # Get the file name of the uploaded image\n",
        "\n",
        "# Load YOLO\n",
        "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = yolo_net.getLayerNames()\n",
        "\n",
        "# Get the output layer names (the layers that produce the final output)\n",
        "output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load class names from coco.names\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Load the uploaded image (trial.jpg)\n",
        "img = cv2.imread(image_path)\n",
        "if img is None:\n",
        "    print(\"Error: Could not load the image.\")\n",
        "else:\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Convert image to blob for YOLO model\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    yolo_net.setInput(blob)\n",
        "    outs = yolo_net.forward(output_layers)\n",
        "\n",
        "    # Process the detections\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            if confidence > 0.5:\n",
        "                # Get the bounding box coordinates\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Draw the bounding box on the image\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maximum Suppression to remove overlapping boxes\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # Draw the detected objects\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indices:\n",
        "            box = boxes[i]\n",
        "            x, y, w, h = box\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = confidences[i]\n",
        "\n",
        "            # Draw a rectangle around the object\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(img, f\"{label} {confidence:.2f}\", (x, y - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the resulting image with detections\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxVLJdWfYwZl"
      },
      "source": [
        "# **Real time Detection**\n",
        "\n",
        "In Google Colab, we **cannot directly access the webcam** feed as we would on our local machine, but there is a workaround."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "agdVJFOPen7m"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "KvsWXSyoen7n",
        "outputId": "c0cf5a97-4296-4f48-9731-0aed78849093"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "G9azVCcher8w",
        "outputId": "e02d4d3b-0135-46be-cd2f-727891faec93"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLO model\n",
        "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = yolo_net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load class labels (COCO names)\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Load the image (photo.jpg)\n",
        "img = cv2.imread(\"photo.jpg\")\n",
        "height, width, channels = img.shape\n",
        "\n",
        "# Convert the image to a blob for YOLO input\n",
        "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "yolo_net.setInput(blob)\n",
        "outs = yolo_net.forward(output_layers)\n",
        "\n",
        "# Post-process the output and draw bounding boxes\n",
        "class_ids = []\n",
        "confidences = []\n",
        "boxes = []\n",
        "\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > 0.5:  # Adjust confidence threshold as needed\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)\n",
        "\n",
        "            # Rectangle coordinates\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "# Apply non-maxima suppression to remove redundant boxes\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "# Draw bounding boxes and labels on the image\n",
        "for i in range(len(boxes)):\n",
        "    if i in indices:\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        confidence = str(round(confidences[i], 2))\n",
        "\n",
        "        # Draw the rectangle and the label\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f\"{label} {confidence}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Convert the image from BGR to RGB (for display in Colab)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optionally, save the processed image with bounding boxes\n",
        "cv2.imwrite(\"photo_detected.jpg\", img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HcrCFufjLL7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
